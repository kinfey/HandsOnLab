{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>NumSharp, 0.30.0</span></li><li><span>SciSharp.TensorFlow.Redist, 2.6.0</span></li><li><span>TensorFlow.Keras, 0.6.4</span></li><li><span>TensorFlow.Net, 0.60.4</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget: TensorFlow.Net\"\n",
    "#r \"nuget: TensorFlow.Keras\"\n",
    "#r \"nuget: SciSharp.TensorFlow.Redist\"\n",
    "#r \"nuget: NumSharp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **线性回归** #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "source": [
    "### **Tensorflow.NET 和Tensorflow 是一致的** ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using System;\n",
    "using Tensorflow;\n",
    "using Tensorflow.NumPy;\n",
    "using static Tensorflow.Binding;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "var X = tf.placeholder(tf.float32);\n",
    "var Y = tf.placeholder(tf.float32);\n",
    "\n",
    "var W = tf.Variable(-0.06f, name: \"weight\");\n",
    "var b = tf.Variable(-0.73f, name: \"bias\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "float learning_rate = 0.01f;\n",
    "int display_step = 50;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "var train_X = np.array(3.3f, 4.4f, 5.5f, 6.71f, 6.93f, 4.168f, 9.779f, 6.182f, 7.59f, 2.167f,\n",
    "    7.042f, 10.791f, 5.313f, 7.997f, 5.654f, 9.27f, 3.1f);\n",
    "var train_Y = np.array(1.7f, 2.76f, 2.09f, 3.19f, 1.694f, 1.573f, 3.366f, 2.596f, 2.53f, 1.221f,\n",
    "    2.827f, 3.465f, 1.65f, 2.904f, 2.42f, 2.94f, 1.3f);\n",
    "var n_samples = (int)train_X.shape[0];\n",
    "\n",
    "int display_step = 50;\n",
    "\n",
    "float learning_rate = 0.01f;\n",
    "\n",
    "int training_epochs = 1000;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "var pred = tf.add(tf.multiply(X, W), b);\n",
    "var cost = tf.reduce_sum(tf.pow(pred - Y, 2.0f)) / (2.0f * n_samples);\n",
    "var optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost);\n",
    "var init = tf.global_variables_initializer();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "var pred = tf.add(tf.multiply(X, W), b);\n",
    "\n",
    "var cost = tf.reduce_sum(tf.pow(pred - Y, 2.0f)) / (2.0f * n_samples);\n",
    "\n",
    " var optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost);\n",
    "\n",
    "var init = tf.global_variables_initializer();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "var sess = tf.Session();\n",
    "// Run the initializer\n",
    "sess.run(init);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50 cost=0.19328241 W=0.44026902 b=-0.57023937\r\n",
      "Epoch: 100 cost=0.17984506 W=0.42892876 b=-0.48865774\r\n",
      "Epoch: 150 cost=0.16795948 W=0.41826284 b=-0.41192815\r\n",
      "Epoch: 200 cost=0.15744655 W=0.40823138 b=-0.33976227\r\n",
      "Epoch: 250 cost=0.14814776 W=0.39879647 b=-0.27188826\r\n",
      "Epoch: 300 cost=0.13992295 W=0.38992265 b=-0.208051\r\n",
      "Epoch: 350 cost=0.13264813 W=0.38157663 b=-0.14801025\r\n",
      "Epoch: 400 cost=0.12621354 W=0.373727 b=-0.09154031\r\n",
      "Epoch: 450 cost=0.12052226 W=0.36634418 b=-0.038428996\r\n",
      "Epoch: 500 cost=0.11548846 W=0.35940045 b=0.011523556\r\n",
      "Epoch: 550 cost=0.111036174 W=0.35286975 b=0.058505252\r\n",
      "Epoch: 600 cost=0.107098304 W=0.34672746 b=0.102692656\r\n",
      "Epoch: 650 cost=0.10361542 W=0.34095046 b=0.14425191\r\n",
      "Epoch: 700 cost=0.10053498 W=0.335517 b=0.18333974\r\n",
      "Epoch: 750 cost=0.09781052 W=0.3304067 b=0.22010279\r\n",
      "Epoch: 800 cost=0.09540092 W=0.32560027 b=0.25467926\r\n",
      "Epoch: 850 cost=0.09326982 W=0.32107988 b=0.28719908\r\n",
      "Epoch: 900 cost=0.09138502 W=0.3168282 b=0.31778553\r\n",
      "Epoch: 950 cost=0.089718156 W=0.31282943 b=0.34655213\r\n",
      "Epoch: 1000 cost=0.08824395 W=0.30906853 b=0.37360826\r\n"
     ]
    }
   ],
   "source": [
    "for (int epoch = 0; epoch < training_epochs; epoch++)\n",
    "{\n",
    "    foreach (var (x, y) in zip<float>(train_X, train_Y))\n",
    "        sess.run(optimizer, (X, x), (Y, y));\n",
    "\n",
    "                // Display logs per epoch step\n",
    "    if ((epoch + 1) % display_step == 0)\n",
    "    {\n",
    "        var c = sess.run(cost, (X, train_X), (Y, train_Y));\n",
    "        Console.WriteLine($\"Epoch: {epoch + 1} cost={c} \" + $\"W={sess.run(W)} b={sess.run(b)}\");\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training cost=0.08824395 W=0.30906853 b=0.37360826\r\n"
     ]
    }
   ],
   "source": [
    "var training_cost = sess.run(cost, (X, train_X), (Y, train_Y));\n",
    "Console.WriteLine($\"Training cost={training_cost} W={sess.run(W)} b={sess.run(b)}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing... (Mean square loss Comparison)\r\n",
      "Testing cost=0.07984468\r\n",
      "Absolute mean square loss difference: 0.008399263\r\n"
     ]
    }
   ],
   "source": [
    "var test_X = np.array(6.83f, 4.668f, 8.9f, 7.91f, 5.7f, 8.7f, 3.1f, 2.1f);\n",
    "var test_Y = np.array(1.84f, 2.273f, 3.2f, 2.831f, 2.92f, 3.24f, 1.35f, 1.03f);\n",
    "Console.WriteLine(\"Testing... (Mean square loss Comparison)\");\n",
    "var testing_cost = sess.run(tf.reduce_sum(tf.pow(pred - Y, 2.0f)) / (2.0f * test_X.shape[0]),(X, test_X), (Y, test_Y));\n",
    "Console.WriteLine($\"Testing cost={testing_cost}\");\n",
    "var diff = Math.Abs((float)training_cost - (float)testing_cost);\n",
    "Console.WriteLine($\"Absolute mean square loss difference: {diff}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using Tensorflow.NumPy;\n",
    "using static Tensorflow.Binding;\n",
    "using static Tensorflow.KerasApi;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "train_X = np.array(3.3f, 4.4f, 5.5f, 6.71f, 6.93f, 4.168f, 9.779f, 6.182f, \n",
    "    7.59f, 2.167f, 7.042f, 10.791f, 5.313f, 7.997f, 5.654f, 9.27f, 3.1f);\n",
    "\n",
    "train_Y = np.array(1.7f, 2.76f, 2.09f, 3.19f, 1.694f, 1.573f, 3.366f, \n",
    "    2.596f, 2.53f, 1.221f, 2.827f, 3.465f, 1.65f, 2.904f, 2.42f, 2.94f, 1.3f);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "tf.enable_eager_execution();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "var layers = keras.layers;\n",
    "var inputs = keras.Input(shape: 1);\n",
    "var outputs = layers.Dense(1).Apply(inputs);\n",
    "var model = keras.Model(inputs, outputs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: functional_2 \r\n",
      "_________________________________________________________________ \r\n",
      "Layer (type)                  Output Shape              Param #   \r\n",
      "================================================================= \r\n",
      "input_3 (InputLayer)          (None, 1)                 0         \r\n",
      "_________________________________________________________________ \r\n",
      "dense_2 (Dense)               (None, 1)                 2         \r\n",
      "================================================================= \r\n",
      "Total params: 2 \r\n",
      "Trainable params: 2 \r\n",
      "Non-trainable params: 0 \r\n",
      "_________________________________________________________________ \r\n"
     ]
    }
   ],
   "source": [
    "model.summary();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    " model.compile(loss: keras.losses.MeanSquaredError(),\n",
    "    optimizer: keras.optimizers.SGD(0.005f),\n",
    "     metrics: new[] { \"acc\" });"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/100, Step: 0001/0001, loss: 56.633942, acc: 0.000000\r\n",
      "Epoch: 002/100, Step: 0001/0001, loss: 17.217974, acc: 0.000000\r\n",
      "Epoch: 003/100, Step: 0001/0001, loss: 5.364075, acc: 0.000000\r\n",
      "Epoch: 004/100, Step: 0001/0001, loss: 1.799015, acc: 0.000000\r\n",
      "Epoch: 005/100, Step: 0001/0001, loss: 0.726693, acc: 0.000000\r\n",
      "Epoch: 006/100, Step: 0001/0001, loss: 0.404020, acc: 0.000000\r\n",
      "Epoch: 007/100, Step: 0001/0001, loss: 0.306792, acc: 0.000000\r\n",
      "Epoch: 008/100, Step: 0001/0001, loss: 0.277364, acc: 0.000000\r\n",
      "Epoch: 009/100, Step: 0001/0001, loss: 0.268326, acc: 0.000000\r\n",
      "Epoch: 010/100, Step: 0001/0001, loss: 0.265420, acc: 0.000000\r\n",
      "Epoch: 011/100, Step: 0001/0001, loss: 0.264359, acc: 0.000000\r\n",
      "Epoch: 012/100, Step: 0001/0001, loss: 0.263853, acc: 0.000000\r\n",
      "Epoch: 013/100, Step: 0001/0001, loss: 0.263515, acc: 0.000000\r\n",
      "Epoch: 014/100, Step: 0001/0001, loss: 0.263228, acc: 0.000000\r\n",
      "Epoch: 015/100, Step: 0001/0001, loss: 0.262956, acc: 0.000000\r\n",
      "Epoch: 016/100, Step: 0001/0001, loss: 0.262689, acc: 0.000000\r\n",
      "Epoch: 017/100, Step: 0001/0001, loss: 0.262424, acc: 0.000000\r\n",
      "Epoch: 018/100, Step: 0001/0001, loss: 0.262161, acc: 0.000000\r\n",
      "Epoch: 019/100, Step: 0001/0001, loss: 0.261898, acc: 0.000000\r\n",
      "Epoch: 020/100, Step: 0001/0001, loss: 0.261636, acc: 0.000000\r\n",
      "Epoch: 021/100, Step: 0001/0001, loss: 0.261375, acc: 0.000000\r\n",
      "Epoch: 022/100, Step: 0001/0001, loss: 0.261114, acc: 0.000000\r\n",
      "Epoch: 023/100, Step: 0001/0001, loss: 0.260853, acc: 0.000000\r\n",
      "Epoch: 024/100, Step: 0001/0001, loss: 0.260594, acc: 0.000000\r\n",
      "Epoch: 025/100, Step: 0001/0001, loss: 0.260335, acc: 0.000000\r\n",
      "Epoch: 026/100, Step: 0001/0001, loss: 0.260077, acc: 0.000000\r\n",
      "Epoch: 027/100, Step: 0001/0001, loss: 0.259819, acc: 0.000000\r\n",
      "Epoch: 028/100, Step: 0001/0001, loss: 0.259562, acc: 0.000000\r\n",
      "Epoch: 029/100, Step: 0001/0001, loss: 0.259305, acc: 0.000000\r\n",
      "Epoch: 030/100, Step: 0001/0001, loss: 0.259049, acc: 0.000000\r\n",
      "Epoch: 031/100, Step: 0001/0001, loss: 0.258794, acc: 0.000000\r\n",
      "Epoch: 032/100, Step: 0001/0001, loss: 0.258540, acc: 0.000000\r\n",
      "Epoch: 033/100, Step: 0001/0001, loss: 0.258286, acc: 0.000000\r\n",
      "Epoch: 034/100, Step: 0001/0001, loss: 0.258032, acc: 0.000000\r\n",
      "Epoch: 035/100, Step: 0001/0001, loss: 0.257780, acc: 0.000000\r\n",
      "Epoch: 036/100, Step: 0001/0001, loss: 0.257527, acc: 0.000000\r\n",
      "Epoch: 037/100, Step: 0001/0001, loss: 0.257276, acc: 0.000000\r\n",
      "Epoch: 038/100, Step: 0001/0001, loss: 0.257025, acc: 0.000000\r\n",
      "Epoch: 039/100, Step: 0001/0001, loss: 0.256775, acc: 0.000000\r\n",
      "Epoch: 040/100, Step: 0001/0001, loss: 0.256525, acc: 0.000000\r\n",
      "Epoch: 041/100, Step: 0001/0001, loss: 0.256276, acc: 0.000000\r\n",
      "Epoch: 042/100, Step: 0001/0001, loss: 0.256027, acc: 0.000000\r\n",
      "Epoch: 043/100, Step: 0001/0001, loss: 0.255780, acc: 0.000000\r\n",
      "Epoch: 044/100, Step: 0001/0001, loss: 0.255532, acc: 0.000000\r\n",
      "Epoch: 045/100, Step: 0001/0001, loss: 0.255286, acc: 0.000000\r\n",
      "Epoch: 046/100, Step: 0001/0001, loss: 0.255039, acc: 0.000000\r\n",
      "Epoch: 047/100, Step: 0001/0001, loss: 0.254794, acc: 0.000000\r\n",
      "Epoch: 048/100, Step: 0001/0001, loss: 0.254549, acc: 0.000000\r\n",
      "Epoch: 049/100, Step: 0001/0001, loss: 0.254305, acc: 0.000000\r\n",
      "Epoch: 050/100, Step: 0001/0001, loss: 0.254061, acc: 0.000000\r\n",
      "Epoch: 051/100, Step: 0001/0001, loss: 0.253818, acc: 0.000000\r\n",
      "Epoch: 052/100, Step: 0001/0001, loss: 0.253576, acc: 0.000000\r\n",
      "Epoch: 053/100, Step: 0001/0001, loss: 0.253334, acc: 0.000000\r\n",
      "Epoch: 054/100, Step: 0001/0001, loss: 0.253092, acc: 0.000000\r\n",
      "Epoch: 055/100, Step: 0001/0001, loss: 0.252851, acc: 0.000000\r\n",
      "Epoch: 056/100, Step: 0001/0001, loss: 0.252611, acc: 0.000000\r\n",
      "Epoch: 057/100, Step: 0001/0001, loss: 0.252372, acc: 0.000000\r\n",
      "Epoch: 058/100, Step: 0001/0001, loss: 0.252133, acc: 0.000000\r\n",
      "Epoch: 059/100, Step: 0001/0001, loss: 0.251894, acc: 0.000000\r\n",
      "Epoch: 060/100, Step: 0001/0001, loss: 0.251656, acc: 0.000000\r\n",
      "Epoch: 061/100, Step: 0001/0001, loss: 0.251419, acc: 0.000000\r\n",
      "Epoch: 062/100, Step: 0001/0001, loss: 0.251182, acc: 0.000000\r\n",
      "Epoch: 063/100, Step: 0001/0001, loss: 0.250946, acc: 0.000000\r\n",
      "Epoch: 064/100, Step: 0001/0001, loss: 0.250711, acc: 0.000000\r\n",
      "Epoch: 065/100, Step: 0001/0001, loss: 0.250476, acc: 0.000000\r\n",
      "Epoch: 066/100, Step: 0001/0001, loss: 0.250241, acc: 0.000000\r\n",
      "Epoch: 067/100, Step: 0001/0001, loss: 0.250007, acc: 0.000000\r\n",
      "Epoch: 068/100, Step: 0001/0001, loss: 0.249774, acc: 0.000000\r\n",
      "Epoch: 069/100, Step: 0001/0001, loss: 0.249541, acc: 0.000000\r\n",
      "Epoch: 070/100, Step: 0001/0001, loss: 0.249309, acc: 0.000000\r\n",
      "Epoch: 071/100, Step: 0001/0001, loss: 0.249078, acc: 0.000000\r\n",
      "Epoch: 072/100, Step: 0001/0001, loss: 0.248847, acc: 0.000000\r\n",
      "Epoch: 073/100, Step: 0001/0001, loss: 0.248616, acc: 0.000000\r\n",
      "Epoch: 074/100, Step: 0001/0001, loss: 0.248386, acc: 0.000000\r\n",
      "Epoch: 075/100, Step: 0001/0001, loss: 0.248157, acc: 0.000000\r\n",
      "Epoch: 076/100, Step: 0001/0001, loss: 0.247928, acc: 0.000000\r\n",
      "Epoch: 077/100, Step: 0001/0001, loss: 0.247700, acc: 0.000000\r\n",
      "Epoch: 078/100, Step: 0001/0001, loss: 0.247472, acc: 0.000000\r\n",
      "Epoch: 079/100, Step: 0001/0001, loss: 0.247245, acc: 0.000000\r\n",
      "Epoch: 080/100, Step: 0001/0001, loss: 0.247019, acc: 0.000000\r\n",
      "Epoch: 081/100, Step: 0001/0001, loss: 0.246793, acc: 0.000000\r\n",
      "Epoch: 082/100, Step: 0001/0001, loss: 0.246567, acc: 0.000000\r\n",
      "Epoch: 083/100, Step: 0001/0001, loss: 0.246342, acc: 0.000000\r\n",
      "Epoch: 084/100, Step: 0001/0001, loss: 0.246118, acc: 0.000000\r\n",
      "Epoch: 085/100, Step: 0001/0001, loss: 0.245894, acc: 0.000000\r\n",
      "Epoch: 086/100, Step: 0001/0001, loss: 0.245671, acc: 0.000000\r\n",
      "Epoch: 087/100, Step: 0001/0001, loss: 0.245448, acc: 0.000000\r\n",
      "Epoch: 088/100, Step: 0001/0001, loss: 0.245226, acc: 0.000000\r\n",
      "Epoch: 089/100, Step: 0001/0001, loss: 0.245004, acc: 0.000000\r\n",
      "Epoch: 090/100, Step: 0001/0001, loss: 0.244783, acc: 0.000000\r\n",
      "Epoch: 091/100, Step: 0001/0001, loss: 0.244562, acc: 0.000000\r\n",
      "Epoch: 092/100, Step: 0001/0001, loss: 0.244342, acc: 0.000000\r\n",
      "Epoch: 093/100, Step: 0001/0001, loss: 0.244123, acc: 0.000000\r\n",
      "Epoch: 094/100, Step: 0001/0001, loss: 0.243904, acc: 0.000000\r\n",
      "Epoch: 095/100, Step: 0001/0001, loss: 0.243685, acc: 0.000000\r\n",
      "Epoch: 096/100, Step: 0001/0001, loss: 0.243467, acc: 0.000000\r\n",
      "Epoch: 097/100, Step: 0001/0001, loss: 0.243250, acc: 0.000000\r\n",
      "Epoch: 098/100, Step: 0001/0001, loss: 0.243033, acc: 0.000000\r\n",
      "Epoch: 099/100, Step: 0001/0001, loss: 0.242817, acc: 0.000000\r\n",
      "Epoch: 100/100, Step: 0001/0001, loss: 0.242601, acc: 0.000000\r\n"
     ]
    }
   ],
   "source": [
    " model.fit(train_X, train_Y, epochs: 100);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "file_extension": ".cs",
   "mimetype": "text/x-csharp",
   "name": "C#",
   "pygments_lexer": "csharp",
   "version": "9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

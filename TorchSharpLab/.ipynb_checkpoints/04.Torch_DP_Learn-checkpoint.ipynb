{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>TorchSharp, 0.96.7</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget: TorchSharp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>libtorch-cuda-11.3-linux-x64, 1.11.0.1</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget: libtorch-cuda-11.3-linux-x64\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [],
   "source": [
    "using TorchSharp;\n",
    "using static TorchSharp.TensorExtensionMethods;\n",
    "using static TorchSharp.torch.distributions;\n",
    "\n",
    "using Microsoft.DotNet.Interactive.Formatting;\n",
    "\n",
    "var style = TensorStringStyle.Julia;\n",
    "\n",
    "Formatter.SetPreferredMimeTypesFor(typeof(torch.Tensor), \"text/plain\");\n",
    "Formatter.Register<torch.Tensor>((torch.Tensor x) => x.ToString(style, newLine: \"\\n\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "source": [
    "## **模型**\n",
    "\n",
    "虽然使用 Torch 进行数值计算是有用且高效的，但无论用 Python、C# 还是 F#，建模都是用 Torch 作为核心 。\n",
    "\n",
    "了解 LibTorch，Pytorch 和 TorchSharp 下的引擎是如何工作的很重要——它是一个动态模型引擎，这意味着该引擎可以跟踪从宿主语言完成的工作，跟踪它并进行能够执行反向传播。这与早期框架的工作方式非常不同，例如 Tensorflow v1.X——在这些框架中，模型图是由主机代码构建的，只有在构建图之后才能运行模型。\n",
    "\n",
    "TF v1.X 的静态方法有一些与之相关的挑战，其中之一是当代码没有急切地运行时很难调试。静态方法的优点之一是外部化整个模型相对简单：它的权重和逻辑。\n",
    "\n",
    "动态框架并非如此——权重和逻辑是紧密相连的，但只是松散的。为了在训练期间和之后执行模型，您需要模型的代码，以宿主语言表示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "source": [
    "## **模型类**\n",
    "\n",
    "通常，我们希望将模型的逻辑保留在它自己的类中。 这使得使用其他 TorchSharp 构造来组合和运行模型变得容易。 从概念上讲，这就是一个模型——一个张量 -> 张量函数，实现为一个具有“forward()”函数的类。 这个函数是放置模型逻辑的地方。 （如果 C# 支持 operator()，就像 C++ 那样，那我们就在这里使用它。就像 Python 一样。）\n",
    "\n",
    "TorchSharp 使构建模型变得容易，因为您只需指定 forward 函数。 要进行反向传播，您还需要后向函数，该函数支持使用微积分的链式法则计算梯度。 在 Torch 中，只要前向函数仅依赖于 Torch API 进行计算，就会自动实现后向函数。\n",
    "\n",
    "让我们从一个超级简单的模型开始，它只有一个线性层，它期望一个具有 1000 个输入元素的张量，并将产生一个具有 100 个元素的张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "using static TorchSharp.torch;\n",
    "\n",
    "using static TorchSharp.torch.nn;\n",
    "using static TorchSharp.torch.nn.functional;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [],
   "source": [
    "private class Trivial : nn.Module\n",
    "{\n",
    "    public Trivial()\n",
    "        : base(nameof(Trivial))\n",
    "    {\n",
    "        RegisterComponents();\n",
    "    }\n",
    "\n",
    "    public override Tensor forward(Tensor input)\n",
    "    {\n",
    "        return lin1.forward(input);\n",
    "    }\n",
    "\n",
    "    private nn.Module lin1 = nn.Linear(1000, 100);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100], type = Float32, device = cpu\n",
       " 0.58924 -0.3256 0.1649 0.22228 -0.15231 -0.12498 -0.32059 -0.21909 0.45464 -0.22725 -0.17543 ...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var input = rand(1000);\n",
    "var model = new Trivial();\n",
    "model.forward(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3x100], type = Float32, device = cpu\n",
       " 0.20076 0.086515 0.16434 -0.12702  0.21787  0.29725 -0.36543   -0.21218 0.14961 -0.10872 ...\n",
       " 0.31423 -0.16598 0.49614 -0.26881 -0.19279  0.11501 -0.21428   -0.35448 0.55196 0.022209 ...\n",
       " 0.23449 -0.37997 0.59868 -0.17393  0.14784 0.038413 -0.41799 -0.0074947 0.46324 -0.20228 ...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.forward(rand(3,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2x3x100], type = Float32, device = cpu\n",
       "[0,..,..] =\n",
       " 0.54354 -0.050132 0.25674  -0.27538  -0.012125 0.12768  -0.4064 -0.22759 0.51197 -0.21235 -0.18049 ...\n",
       " 0.36969  -0.23157 0.49817 -0.026331    0.13588  0.1565 -0.66135 -0.22795 0.56968 -0.13282 -0.39739 ...\n",
       " 0.23221  -0.17621 0.12943   0.06133 -0.0010741 0.15685 -0.31468 -0.30573 0.70008 -0.21448 -0.27042 ...\n",
       "\n",
       "[1,..,..] =\n",
       " 0.12672 -0.23669 0.69381 -0.011724   0.35251 0.53432 -0.45561 -0.0073498 0.52984 -0.018081 ...\n",
       " 0.39906 -0.10035  0.3624   -0.1719   0.37989 0.12773 -0.37688  -0.022094 0.32009  0.038945 ...\n",
       " 0.26549 -0.35346 0.36921  -0.38581 -0.059927 0.44854 -0.31564   -0.24862 0.68627  -0.26292 ...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.forward(rand(2,3,1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所有 TorchSharp 运算符都将接受批处理或非批处理输入数据，但并非所有运算符都将接受一个以上的先前维度。 线性在这方面并不是唯一的，但通常情况并非如此。\n",
    "\n",
    "如果我们只想使用单个线性层，那么严格来说，模型类就不是必需的。 该类的真正价值，与大多数现实世界的场景相匹配，是在模型中组合多个运算符，并将其抽象（隐藏）于外部世界。 我们可以做的最简单的添加就是将 ReLU 添加到模型中。\n",
    "\n",
    "由于 ReLU 和所有激活函数一样，不依赖于可训练的权重，因此无需创建模块并将其保存在字段中，我们可以将其作为函数调用。 ReLU 也有一个模块版本，它有它的用途，但在这种情况下，它是矫枉过正的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [],
   "source": [
    "private class Trivial : nn.Module\n",
    "{\n",
    "    public Trivial()\n",
    "        : base(nameof(Trivial))\n",
    "    {\n",
    "        RegisterComponents();\n",
    "    }\n",
    "\n",
    "    public override Tensor forward(Tensor input)\n",
    "    {\n",
    "        using var x = lin1.forward(input);\n",
    "        return nn.functional.relu(x);\n",
    "    }\n",
    "\n",
    "    private nn.Module lin1 = nn.Linear(1000, 100);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100], type = Float32, device = cpu\n",
       " 0 0.10657 0 0 0.011773 0 0.37909 0 0 0 0.10858 0 0 0.0031786 0 0.24584 0 1.1918 0 0 0.12788 ...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var input = rand(1000);\n",
    "var model = new Trivial();\n",
    "model.forward(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [],
   "source": [
    "private class Trivial : nn.Module\n",
    "{\n",
    "    public Trivial()\n",
    "        : base(nameof(Trivial))\n",
    "    {\n",
    "        RegisterComponents();\n",
    "    }\n",
    "\n",
    "    public override Tensor forward(Tensor input)\n",
    "    {\n",
    "        using var x = lin1.forward(input);\n",
    "        using var y = nn.functional.relu(x);\n",
    "        return lin2.forward(y);\n",
    "    }\n",
    "\n",
    "    private nn.Module lin1 = nn.Linear(1000, 100);\n",
    "    private nn.Module lin2 = nn.Linear(100, 10);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10], type = Float32, device = cpu\n",
       " 0.11489 -0.11035 0.074485 0.005859 0.064043 0.21116 -0.13207 -0.049393 -0.055822 -0.29107\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var model = new Trivial();\n",
    "model.forward(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32x1000], type = Float32, device = cpu"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var dataBatch = rand(32,1000);  // Our pretend input data\n",
    "var resultBatch = rand(32,10);  // Our pretend ground truth.\n",
    "dataBatch.ToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"dni-plaintext\">0.3450216</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var loss = nn.functional.mse_loss();\n",
    "loss(model.forward(dataBatch), resultBatch).item<float>()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "source": [
    "## **训练**\n",
    "\n",
    "训练包括重复计算损失，然后是梯度，然后在重新开始之前将梯度应用于模型权重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"dni-plaintext\">0.34260148</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var learning_rate = 0.001f;\n",
    "\n",
    "// Compute the loss\n",
    "var output = loss(model.forward(dataBatch), resultBatch);\n",
    "\n",
    "// Clear the gradients before doing the back-propagation\n",
    "model.zero_grad();\n",
    "\n",
    "// Do back-progatation, which computes all the gradients.\n",
    "output.backward();\n",
    "\n",
    "// Adjust the weights using the gradients.\n",
    "using (torch.no_grad()) {\n",
    "    foreach (var param in model.parameters()) {\n",
    "        var grad = param.grad();\n",
    "        if (grad is not null) {\n",
    "            var update = grad.mul(learning_rate);\n",
    "            param.sub_(update);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "loss(model.forward(dataBatch), resultBatch).item<float>()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "source": [
    "## **优化器**\n",
    "\n",
    "上述训练逻辑的最后一步称为“优化”，它在数学意义上使用：我们正在最小化损失函数，即找到损失最小的输入。 请注意，我们不是针对输入数据将其最小化，而是针对权重进行最小化。\n",
    "\n",
    "像上面那样显式地写出最小化步骤将变得非常乏味，并且存在比上面简单的优化方法（梯度下降）更复杂的优化方法。 这些被适当地称为“优化器”的类中捕获。 我们可以使用优化器并使用它来调整权重，而不是执行上述操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"dni-plaintext\">0.3378535</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var learning_rate = 0.001f;\n",
    "\n",
    "var optimizer = torch.optim.SGD(model.parameters(), learning_rate);\n",
    "\n",
    "// Compute the loss\n",
    "var output = loss(model.forward(dataBatch), resultBatch);\n",
    "\n",
    "// Clear the gradients before doing the back-propagation\n",
    "model.zero_grad();\n",
    "\n",
    "// Do back-progatation, which computes all the gradients.\n",
    "output.backward();\n",
    "\n",
    "optimizer.step();\n",
    "\n",
    "loss(model.forward(dataBatch), resultBatch).item<float>()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"dni-plaintext\">0.2763172</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var learning_rate = 0.01f;\n",
    "\n",
    "var optimizer = torch.optim.SGD(model.parameters(), learning_rate);\n",
    "\n",
    "// Compute the loss\n",
    "var output = loss(model.forward(dataBatch), resultBatch);\n",
    "\n",
    "// Clear the gradients before doing the back-propagation\n",
    "model.zero_grad();\n",
    "\n",
    "// Do back-progatation, which computes all the gradients.\n",
    "output.backward();\n",
    "\n",
    "optimizer.step();\n",
    "\n",
    "loss(model.forward(dataBatch), resultBatch).item<float>()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"dni-plaintext\">0.12968187</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var optimizer = torch.optim.Adam(model.parameters());\n",
    "\n",
    "// Compute the loss\n",
    "var output = loss(model.forward(dataBatch), resultBatch);\n",
    "\n",
    "// Clear the gradients before doing the back-propagation\n",
    "model.zero_grad();\n",
    "\n",
    "// Do back-progatation, which computes all the gradients.\n",
    "output.backward();\n",
    "\n",
    "optimizer.step();\n",
    "\n",
    "loss(model.forward(dataBatch), resultBatch).item<float>()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"dni-plaintext\">0.030665454</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var learning_rate = 0.01f;\n",
    "model = new Trivial();\n",
    "\n",
    "var optimizer = torch.optim.SGD(model.parameters(), learning_rate);\n",
    "\n",
    "for (int i = 0; i < 1000; i++) {\n",
    "    // Compute the loss\n",
    "    using var output = loss(model.forward(dataBatch), resultBatch);\n",
    "\n",
    "    // Clear the gradients before doing the back-propagation\n",
    "    model.zero_grad();\n",
    "\n",
    "    // Do back-progatation, which computes all the gradients.\n",
    "    output.backward();\n",
    "\n",
    "    optimizer.step();\n",
    "}\n",
    "\n",
    "loss(model.forward(dataBatch), resultBatch).item<float>()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **准确性**\n",
    "\n",
    "损失对于优化很有用，但它相对粗略地表明了模型实际上有多好。 事实上，它在很大程度上是无用的。 我们真正关心的是它在做出预测时有多准确。 为此，我们需要计算正确预测的数量并除以批量大小。\n",
    "\n",
    "为此，我们必须对如何解释模型的输出有所了解。 在这种情况下，每个预测都是一个十元素张量。 我们怎么读？ 让我们决定将模型解释为识别具有最大输出值的索引。 TorchSharp 有一个功能可以做到这一点，我们可以在模型训练后使用它来评估模型。\n",
    "\n",
    "对于基本事实，以下是最大值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32], type = Int64, device = cpu\n",
       " 9 7 9 3 9 6 0 2 8 5 2 0 5 8 7 0 8 9 4 9 8 5 1 1 0 3 6 7 5 2 6 9\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var refMax = resultBatch.argmax(1);\n",
    "refMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32], type = Int64, device = cpu\n",
       " 9 0 1 3 2 6 0 2 8 0 1 0 0 1 6 0 2 1 8 0 7 0 1 0 7 9 6 7 0 8 6 2\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var predMax = model.forward(dataBatch).argmax(1);\n",
    "predMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[], type = Float32, device = cpu, value = 0.375"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(refMax == predMax).sum() / predMax.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[], type = Float32, device = cpu, value = 0.1875"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var x = rand(64,1000);  // Our pretend input data\n",
    "var y = rand(64,10);    // Our pretend ground truth.\n",
    "\n",
    "var yMax = y.argmax(1);\n",
    "var pMax = model.forward(x).argmax(1);\n",
    "\n",
    "(yMax == pMax).sum() / refMax.numel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "file_extension": ".cs",
   "mimetype": "text/x-csharp",
   "name": "C#",
   "pygments_lexer": "csharp",
   "version": "10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

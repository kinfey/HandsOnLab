{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>TorchSharp, 0.96.7</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget: TorchSharp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>libtorch-cuda-11.3-linux-x64, 1.11.0.1</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget: libtorch-cuda-11.3-linux-x64\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **使用 cuda**\n",
    "\n",
    "当您的机器配备支持 CUDA 编程的 GPU 时，您可以使用“TorchSharp-cuda-windows”或“TorchSharp-cuda-linux”，具体取决于您的操作系统。 MacOS 没有 CUDA 发行版。\n",
    "\n",
    "使用 CUDA，尤其是用于训练，可以显着提高性能，通常提高几个数量级。这可能是模型训练可行与不可行之间的区别。\n",
    "\n",
    "注意：这些教程对功能的要求并不高，但要训练具有适度数据大小的真实视觉模型，您至少需要 8MB 的专用 GPU 内存。即使像 CIFAR10 这样简单的东西（在这个 repo 的示例解决方案中）也需要那么多内存才能不爆炸。 6MB，在支持 Nvidia 的笔记本电脑上的常见内存大小，是不够的。\n",
    "\n",
    "安装正确的后端包后，使用 CUDA 非常简单。 TorchSharp 让您可以像在 CPU 上一样轻松地在 GPU 上创建和使用张量。以前，我们在创建张量时没有使用 'device' 参数，但它很容易使用。请注意，字符串表示看起来有所不同——它表示设备的“cuda:0”而不是“cpu”。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [],
   "source": [
    "using TorchSharp;\n",
    "using static TorchSharp.TensorExtensionMethods;\n",
    "using static TorchSharp.torch.distributions;\n",
    "\n",
    "using Microsoft.DotNet.Interactive.Formatting;\n",
    "\n",
    "var style = TensorStringStyle.Julia;\n",
    "\n",
    "Formatter.SetPreferredMimeTypesFor(typeof(torch.Tensor), \"text/plain\");\n",
    "Formatter.Register<torch.Tensor>((torch.Tensor x) => x.ToString(style, newLine: \"\\n\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3x4], type = Float32, device = cuda:0\n",
       " 1 1 1 1\n",
       " 1 1 1 1\n",
       " 1 1 1 1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.ones(3,4, device: torch.CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3x4], type = Float32, device = cuda:0\n",
      " 2 2 2 2\n",
      " 2 2 2 2\n",
      " 2 2 2 2\n",
      "\n",
      "[3x4], type = Float32, device = cuda:0\n",
      " 2 2 2 2\n",
      " 2 2 2 2\n",
      " 2 2 2 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var a = torch.ones(3,4, device: torch.CUDA);\n",
    "var b = torch.ones(3,4, device: torch.CUDA);\n",
    "var c = torch.ones(3,4, device: torch.CUDA);\n",
    "\n",
    "(a + b).print();\n",
    "(a + c).print();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3x4], type = Float32, device = cuda:0\n",
      " 2 2 2 2\n",
      " 2 2 2 2\n",
      " 2 2 2 2\n",
      "\n",
      "[3x4], type = Float32, device = cuda:0\n",
      " 1 1 1 1\n",
      " 1 1 1 1\n",
      " 1 1 1 1\n",
      "\n",
      "[3x4], type = Float32, device = cuda:0\n",
      " 2 2 2 2\n",
      " 2 2 2 2\n",
      " 2 2 2 2\n",
      "\n",
      "[3x4], type = Float32, device = cuda:0\n",
      " 1 1 1 1\n",
      " 1 1 1 1\n",
      " 1 1 1 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(a + c.cuda()).print();\n",
    "c.print();\n",
    "\n",
    "// or:\n",
    "\n",
    "(a + c.to(device:torch.CUDA)).print();\n",
    "c.print();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "source": [
    "## **GPU 内存管理**\n",
    "\n",
    "在继续之前，重要的是讨论张量的显式内存管理。 因为 CUDA 没有任何虚拟内存机制，所以很容易耗尽 GPU 内存，除非仔细管理。\n",
    "\n",
    "TorchSharp 张量最终被垃圾收集，当堆开始变满时触发。 但是，堆是所有 CPU 内存，并且只有托管运行时可以看到的内存。 张量的存储是在本机代码中分配的，因此不会增加触发 GC 的内存压力。 这对于 GPU 内存来说尤其不稳定。\n",
    "\n",
    "因此，tensor 类实现了 IDisposable，这样就可以手动释放内存。\n",
    "\n",
    "TorchSharp 算法会产生很多临时的，不再使用时需要释放。 考虑这个表达式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3x4], type = Float32, device = cuda:0\n",
       " 4 4 4 4\n",
       " 4 4 4 4\n",
       " 4 4 4 4\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(a + b) * (a + c.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [],
   "source": [
    "var t0 = a + b;\n",
    "var t1 = c.cuda();\n",
    "var t2 = a + t1;\n",
    "var t3 = t0 * t2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3x4], type = Float32, device = cuda:0\n",
      " 4 4 4 4\n",
      " 4 4 4 4\n",
      " 4 4 4 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "using (torch.Tensor t0 = a + b, t1 = c.cuda(), t2 = a + t1 ) {\n",
    "\n",
    "    var t3 = t0 * t2;\n",
    "    t3.print();\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "source": [
    "## **处置范围**\n",
    "\n",
    "在 0.95.4 版本中，TorchSharp 引入了 DisposeScope 的概念，它系统地处理了 dispose 模式。 它引入了动态（运行时）作用域的概念，它控制作用域有效时创建的所有张量的提升时间。 词法范围，即保存变量的源代码位置等，对动态范围管理没有影响。\n",
    "\n",
    "当任何 .NET 张量被创建时，它会被注册到当前的动态范围（如果有的话）。 一旦注册，张量将在释放范围时自动释放。 张量是否保存在范围外或范围内声明的变量中都没有关系。\n",
    "\n",
    "尝试使用和不使用“使用”行运行下一个单元格（将其注释掉），并注意如果你没有它，张量计数如何增长，但当你这样做时保持不变。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "725\n",
      "[3x4], type = Float32, device = cuda:0\n",
      " 4 4 4 4\n",
      " 4 4 4 4\n",
      " 4 4 4 4\n",
      "\n",
      "725\n"
     ]
    }
   ],
   "source": [
    "Console.WriteLine(torch.Tensor.TotalCount);\n",
    "using (var d = torch.NewDisposeScope()) \n",
    "{\n",
    "    var t3 = (a + b) * (a + c.cuda());\n",
    "    t3.print();\n",
    "}\n",
    "Console.WriteLine(torch.Tensor.TotalCount);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [
    {
     "ename": "Error",
     "evalue": "System.InvalidOperationException: Tensor invalid -- empty handle.\n   at TorchSharp.torch.Tensor.get_Handle()\n   at TorchSharp.torch.Tensor.get_device_type()\n   at TorchSharp.torch.Tensor.ToString(TensorStringStyle style, String fltFormat, Int32 width, CultureInfo cultureInfo, String newLine)\n   at TorchSharp.TensorExtensionMethods.str(Tensor tensor, TensorStringStyle style, String fltFormat, Int32 width, String newLine, CultureInfo cultureInfo)\n   at TorchSharp.TensorExtensionMethods.print(Tensor t, TensorStringStyle style, String fltFormat, Int32 width, String newLine)\n   at Submission#12.<<Initialize>>d__0.MoveNext()\n--- End of stack trace from previous location ---\n   at Microsoft.CodeAnalysis.Scripting.ScriptExecutionState.RunSubmissionsAsync[TResult](ImmutableArray`1 precedingExecutors, Func`2 currentExecutor, StrongBox`1 exceptionHolderOpt, Func`2 catchExceptionOpt, CancellationToken cancellationToken)",
     "output_type": "error",
     "traceback": [
      "System.InvalidOperationException: Tensor invalid -- empty handle.\n",
      "   at TorchSharp.torch.Tensor.get_Handle()\n",
      "   at TorchSharp.torch.Tensor.get_device_type()\n",
      "   at TorchSharp.torch.Tensor.ToString(TensorStringStyle style, String fltFormat, Int32 width, CultureInfo cultureInfo, String newLine)\n",
      "   at TorchSharp.TensorExtensionMethods.str(Tensor tensor, TensorStringStyle style, String fltFormat, Int32 width, String newLine, CultureInfo cultureInfo)\n",
      "   at TorchSharp.TensorExtensionMethods.print(Tensor t, TensorStringStyle style, String fltFormat, Int32 width, String newLine)\n",
      "   at Submission#12.<<Initialize>>d__0.MoveNext()\n",
      "--- End of stack trace from previous location ---\n",
      "   at Microsoft.CodeAnalysis.Scripting.ScriptExecutionState.RunSubmissionsAsync[TResult](ImmutableArray`1 precedingExecutors, Func`2 currentExecutor, StrongBox`1 exceptionHolderOpt, Func`2 catchExceptionOpt, CancellationToken cancellationToken)"
     ]
    }
   ],
   "source": [
    "torch.Tensor t3;\n",
    "using (var d = torch.NewDisposeScope()) \n",
    "{\n",
    "    t3 = (a + b) * (a + c.cuda());\n",
    "}\n",
    "t3.print();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3x4], type = Float32, device = cuda:0\n",
      " 4 4 4 4\n",
      " 4 4 4 4\n",
      " 4 4 4 4\n",
      "\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "torch.Tensor t3;\n",
    "using (var d = torch.NewDisposeScope()) \n",
    "{\n",
    "    t3 = d.MoveToOuter((a + b) * (a + c.cuda()));\n",
    "}\n",
    "t3.print();\n",
    "Console.WriteLine(t3.IsInvalid);\n",
    "t3.Dispose();\n",
    "Console.WriteLine(t3.IsInvalid);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3x4], type = Float32, device = cuda:0\n",
      " 4 4 4 4\n",
      " 4 4 4 4\n",
      " 4 4 4 4\n",
      "\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "torch.Tensor t3;\n",
    "using (var d0 = torch.NewDisposeScope()) \n",
    "{\n",
    "    using (var d1 = torch.NewDisposeScope()) \n",
    "    {\n",
    "        t3 = d1.MoveToOuter((a + b) * (a + c.cuda()));\n",
    "    }\n",
    "    t3.print();\n",
    "    Console.WriteLine(t3.IsInvalid);\n",
    "}\n",
    "Console.WriteLine(t3.IsInvalid);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "source": [
    "## **在 GPU 上放置模型参数**\n",
    "\n",
    "要使用 GPU，必须将张量复制或移动到那里。 当你训练时，你的数据准备逻辑负责将数据传输到 GPU，但我们也需要那里的权重。 TorchSharp 通过在模块上定义一个 'to()' 方法来支持这一点，该方法可用于将模型依赖的权重移动（而不是复制）到 GPU（或返回到 CPU）。 我们还没有查看模型，但请记住这一点以备后用：\n",
    "\n",
    "var model = ...;\n",
    "model.to(torch.CUDA);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "file_extension": ".cs",
   "mimetype": "text/x-csharp",
   "name": "C#",
   "pygments_lexer": "csharp",
   "version": "10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
